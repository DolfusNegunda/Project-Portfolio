{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression - Statistical model selection\n",
    "## Fitting a multiple linear regression on sales of carseats and introducing key concepts for dealing with categorical data and model selection methodology.\n",
    "## Model selection will be based on statistical significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Importing libraries and loading data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from ISLP import load_data\n",
    "\n",
    "from ISLP.models import (ModelSpec as MS, summarize, poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sales</th>\n",
       "      <th>CompPrice</th>\n",
       "      <th>Income</th>\n",
       "      <th>Advertising</th>\n",
       "      <th>Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>ShelveLoc</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Urban</th>\n",
       "      <th>US</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.50</td>\n",
       "      <td>138</td>\n",
       "      <td>73</td>\n",
       "      <td>11</td>\n",
       "      <td>276</td>\n",
       "      <td>120</td>\n",
       "      <td>Bad</td>\n",
       "      <td>42</td>\n",
       "      <td>17</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.22</td>\n",
       "      <td>111</td>\n",
       "      <td>48</td>\n",
       "      <td>16</td>\n",
       "      <td>260</td>\n",
       "      <td>83</td>\n",
       "      <td>Good</td>\n",
       "      <td>65</td>\n",
       "      <td>10</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.06</td>\n",
       "      <td>113</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>269</td>\n",
       "      <td>80</td>\n",
       "      <td>Medium</td>\n",
       "      <td>59</td>\n",
       "      <td>12</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.40</td>\n",
       "      <td>117</td>\n",
       "      <td>100</td>\n",
       "      <td>4</td>\n",
       "      <td>466</td>\n",
       "      <td>97</td>\n",
       "      <td>Medium</td>\n",
       "      <td>55</td>\n",
       "      <td>14</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.15</td>\n",
       "      <td>141</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>340</td>\n",
       "      <td>128</td>\n",
       "      <td>Bad</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sales  CompPrice  Income  Advertising  Population  Price ShelveLoc  Age  \\\n",
       "0   9.50        138      73           11         276    120       Bad   42   \n",
       "1  11.22        111      48           16         260     83      Good   65   \n",
       "2  10.06        113      35           10         269     80    Medium   59   \n",
       "3   7.40        117     100            4         466     97    Medium   55   \n",
       "4   4.15        141      64            3         340    128       Bad   38   \n",
       "\n",
       "   Education Urban   US  \n",
       "0         17   Yes  Yes  \n",
       "1         10   Yes  Yes  \n",
       "2         12   Yes  Yes  \n",
       "3         14   Yes  Yes  \n",
       "4         13   Yes   No  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Carseats = load_data('Carseats')\n",
    "Carseats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Carseats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the purpose of this exercise assume the relevant steps have been taken in preparing and processing the data and ensuring that it is clean and usable. For references check other projects in the github repository.\n",
    "### This dataset contains 400 entries and 11 features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Fitting a multiple linear regression**\n",
    "\n",
    "### Fitting a multiple linear regression to predict sales using 10 predictors containing qualitative and quantitative data.\n",
    "### Urban indicates whether sales took place in an urban area and US indicates if the transaction was made in the US\n",
    "### Using a **backward model selection**, we start with all predictors and remove any features that are statistically insignificant using the p-value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.873</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.870</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   243.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Aug 2023</td> <th>  Prob (F-statistic):</th> <td>1.60e-166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:26:58</td>     <th>  Log-Likelihood:    </th> <td> -568.99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   1162.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   388</td>      <th>  BIC:               </th> <td>   1210.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>         <td>    5.6606</td> <td>    0.603</td> <td>    9.380</td> <td> 0.000</td> <td>    4.474</td> <td>    6.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CompPrice</th>         <td>    0.0928</td> <td>    0.004</td> <td>   22.378</td> <td> 0.000</td> <td>    0.085</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>            <td>    0.0158</td> <td>    0.002</td> <td>    8.565</td> <td> 0.000</td> <td>    0.012</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Advertising</th>       <td>    0.1231</td> <td>    0.011</td> <td>   11.066</td> <td> 0.000</td> <td>    0.101</td> <td>    0.145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Population</th>        <td>    0.0002</td> <td>    0.000</td> <td>    0.561</td> <td> 0.575</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price</th>             <td>   -0.0954</td> <td>    0.003</td> <td>  -35.700</td> <td> 0.000</td> <td>   -0.101</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShelveLoc[Good]</th>   <td>    4.8502</td> <td>    0.153</td> <td>   31.678</td> <td> 0.000</td> <td>    4.549</td> <td>    5.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShelveLoc[Medium]</th> <td>    1.9567</td> <td>    0.126</td> <td>   15.516</td> <td> 0.000</td> <td>    1.709</td> <td>    2.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>               <td>   -0.0460</td> <td>    0.003</td> <td>  -14.472</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Education</th>         <td>   -0.0211</td> <td>    0.020</td> <td>   -1.070</td> <td> 0.285</td> <td>   -0.060</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Urban[Yes]</th>        <td>    0.1229</td> <td>    0.113</td> <td>    1.088</td> <td> 0.277</td> <td>   -0.099</td> <td>    0.345</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>US[Yes]</th>           <td>   -0.1841</td> <td>    0.150</td> <td>   -1.229</td> <td> 0.220</td> <td>   -0.479</td> <td>    0.111</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.811</td> <th>  Durbin-Watson:     </th> <td>   2.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.667</td> <th>  Jarque-Bera (JB):  </th> <td>   0.765</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.107</td> <th>  Prob(JB):          </th> <td>   0.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.994</td> <th>  Cond. No.          </th> <td>4.15e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 4.15e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Sales       & \\textbf{  R-squared:         } &     0.873   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.870   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     243.4   \\\\\n",
       "\\textbf{Date:}             & Fri, 04 Aug 2023 & \\textbf{  Prob (F-statistic):} & 1.60e-166   \\\\\n",
       "\\textbf{Time:}             &     17:26:58     & \\textbf{  Log-Likelihood:    } &   -568.99   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     1162.   \\\\\n",
       "\\textbf{Df Residuals:}     &         388      & \\textbf{  BIC:               } &     1210.   \\\\\n",
       "\\textbf{Df Model:}         &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{intercept}         &       5.6606  &        0.603     &     9.380  &         0.000        &        4.474    &        6.847     \\\\\n",
       "\\textbf{CompPrice}         &       0.0928  &        0.004     &    22.378  &         0.000        &        0.085    &        0.101     \\\\\n",
       "\\textbf{Income}            &       0.0158  &        0.002     &     8.565  &         0.000        &        0.012    &        0.019     \\\\\n",
       "\\textbf{Advertising}       &       0.1231  &        0.011     &    11.066  &         0.000        &        0.101    &        0.145     \\\\\n",
       "\\textbf{Population}        &       0.0002  &        0.000     &     0.561  &         0.575        &       -0.001    &        0.001     \\\\\n",
       "\\textbf{Price}             &      -0.0954  &        0.003     &   -35.700  &         0.000        &       -0.101    &       -0.090     \\\\\n",
       "\\textbf{ShelveLoc[Good]}   &       4.8502  &        0.153     &    31.678  &         0.000        &        4.549    &        5.151     \\\\\n",
       "\\textbf{ShelveLoc[Medium]} &       1.9567  &        0.126     &    15.516  &         0.000        &        1.709    &        2.205     \\\\\n",
       "\\textbf{Age}               &      -0.0460  &        0.003     &   -14.472  &         0.000        &       -0.052    &       -0.040     \\\\\n",
       "\\textbf{Education}         &      -0.0211  &        0.020     &    -1.070  &         0.285        &       -0.060    &        0.018     \\\\\n",
       "\\textbf{Urban[Yes]}        &       0.1229  &        0.113     &     1.088  &         0.277        &       -0.099    &        0.345     \\\\\n",
       "\\textbf{US[Yes]}           &      -0.1841  &        0.150     &    -1.229  &         0.220        &       -0.479    &        0.111     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.811 & \\textbf{  Durbin-Watson:     } &    2.013  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.667 & \\textbf{  Jarque-Bera (JB):  } &    0.765  \\\\\n",
       "\\textbf{Skew:}          &  0.107 & \\textbf{  Prob(JB):          } &    0.682  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.994 & \\textbf{  Cond. No.          } & 4.15e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 4.15e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.873\n",
       "Model:                            OLS   Adj. R-squared:                  0.870\n",
       "Method:                 Least Squares   F-statistic:                     243.4\n",
       "Date:                Fri, 04 Aug 2023   Prob (F-statistic):          1.60e-166\n",
       "Time:                        17:26:58   Log-Likelihood:                -568.99\n",
       "No. Observations:                 400   AIC:                             1162.\n",
       "Df Residuals:                     388   BIC:                             1210.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "intercept             5.6606      0.603      9.380      0.000       4.474       6.847\n",
       "CompPrice             0.0928      0.004     22.378      0.000       0.085       0.101\n",
       "Income                0.0158      0.002      8.565      0.000       0.012       0.019\n",
       "Advertising           0.1231      0.011     11.066      0.000       0.101       0.145\n",
       "Population            0.0002      0.000      0.561      0.575      -0.001       0.001\n",
       "Price                -0.0954      0.003    -35.700      0.000      -0.101      -0.090\n",
       "ShelveLoc[Good]       4.8502      0.153     31.678      0.000       4.549       5.151\n",
       "ShelveLoc[Medium]     1.9567      0.126     15.516      0.000       1.709       2.205\n",
       "Age                  -0.0460      0.003    -14.472      0.000      -0.052      -0.040\n",
       "Education            -0.0211      0.020     -1.070      0.285      -0.060       0.018\n",
       "Urban[Yes]            0.1229      0.113      1.088      0.277      -0.099       0.345\n",
       "US[Yes]              -0.1841      0.150     -1.229      0.220      -0.479       0.111\n",
       "==============================================================================\n",
       "Omnibus:                        0.811   Durbin-Watson:                   2.013\n",
       "Prob(Omnibus):                  0.667   Jarque-Bera (JB):                0.765\n",
       "Skew:                           0.107   Prob(JB):                        0.682\n",
       "Kurtosis:                       2.994   Cond. No.                     4.15e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.15e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperating target variable and predictors and using modelspec() to create a model matrix\n",
    "predictors = list(Carseats.columns.drop(['Sales']))\n",
    "X = MS(predictors).fit_transform(Carseats)\n",
    "y = Carseats['Sales']\n",
    "\n",
    "# Fitting a linear regression\n",
    "model = sm.OLS(y, X)\n",
    "rslt = model.fit()\n",
    "rslt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the modelspec(), the model-matrix builder has created a `ShelveLoc[Good]` dummy variable that takes on a value of 1 if the shelving location is good, and 0 otherwise and has also created a `ShelveLoc[Medium]` dummy variable that equals 1 if the shelving location is medium, and 0 otherwise, lastly a bad shelving location corresponds zero for each of the two dummy variables. This process is repeated for Urban and US feature which only has 2 levels in the dummy variable. **This an example of one hot coding, a necessary step in processing categorical data for regression analysis**.\n",
    "### Using the p-values, **we can reject the null hypotheses** (which states that the coefficients are 0) for predictors that have a **p-value less than 0.05** which leaves 6 of our preditors except Population, Education, Urban, and US. This is to say that the population, education level and location is statistically insignificant in determining sales of car seats.\n",
    "### Using this information we can further reduce our model by removing the insignficant features and compare its results with our full model. This is the process of backward model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>Sales</td>      <th>  R-squared:         </th> <td>   0.872</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.870</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   381.4</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Aug 2023</td> <th>  Prob (F-statistic):</th> <td>1.25e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:49:15</td>     <th>  Log-Likelihood:    </th> <td> -571.24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   1158.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   392</td>      <th>  BIC:               </th> <td>   1190.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     7</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>intercept</th>         <td>    5.4752</td> <td>    0.505</td> <td>   10.842</td> <td> 0.000</td> <td>    4.482</td> <td>    6.468</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CompPrice</th>         <td>    0.0926</td> <td>    0.004</td> <td>   22.451</td> <td> 0.000</td> <td>    0.084</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Income</th>            <td>    0.0158</td> <td>    0.002</td> <td>    8.590</td> <td> 0.000</td> <td>    0.012</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Advertising</th>       <td>    0.1159</td> <td>    0.008</td> <td>   15.006</td> <td> 0.000</td> <td>    0.101</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Price</th>             <td>   -0.0953</td> <td>    0.003</td> <td>  -35.699</td> <td> 0.000</td> <td>   -0.101</td> <td>   -0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShelveLoc[Good]</th>   <td>    4.8357</td> <td>    0.152</td> <td>   31.710</td> <td> 0.000</td> <td>    4.536</td> <td>    5.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ShelveLoc[Medium]</th> <td>    1.9520</td> <td>    0.125</td> <td>   15.569</td> <td> 0.000</td> <td>    1.706</td> <td>    2.198</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Age</th>               <td>   -0.0461</td> <td>    0.003</td> <td>  -14.521</td> <td> 0.000</td> <td>   -0.052</td> <td>   -0.040</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.766</td> <th>  Durbin-Watson:     </th> <td>   1.988</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.682</td> <th>  Jarque-Bera (JB):  </th> <td>   0.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.104</td> <th>  Prob(JB):          </th> <td>   0.667</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.929</td> <th>  Cond. No.          </th> <td>1.91e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.91e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &      Sales       & \\textbf{  R-squared:         } &     0.872   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.870   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     381.4   \\\\\n",
       "\\textbf{Date:}             & Fri, 04 Aug 2023 & \\textbf{  Prob (F-statistic):} & 1.25e-170   \\\\\n",
       "\\textbf{Time:}             &     17:49:15     & \\textbf{  Log-Likelihood:    } &   -571.24   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     1158.   \\\\\n",
       "\\textbf{Df Residuals:}     &         392      & \\textbf{  BIC:               } &     1190.   \\\\\n",
       "\\textbf{Df Model:}         &           7      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                           & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{intercept}         &       5.4752  &        0.505     &    10.842  &         0.000        &        4.482    &        6.468     \\\\\n",
       "\\textbf{CompPrice}         &       0.0926  &        0.004     &    22.451  &         0.000        &        0.084    &        0.101     \\\\\n",
       "\\textbf{Income}            &       0.0158  &        0.002     &     8.590  &         0.000        &        0.012    &        0.019     \\\\\n",
       "\\textbf{Advertising}       &       0.1159  &        0.008     &    15.006  &         0.000        &        0.101    &        0.131     \\\\\n",
       "\\textbf{Price}             &      -0.0953  &        0.003     &   -35.699  &         0.000        &       -0.101    &       -0.090     \\\\\n",
       "\\textbf{ShelveLoc[Good]}   &       4.8357  &        0.152     &    31.710  &         0.000        &        4.536    &        5.135     \\\\\n",
       "\\textbf{ShelveLoc[Medium]} &       1.9520  &        0.125     &    15.569  &         0.000        &        1.706    &        2.198     \\\\\n",
       "\\textbf{Age}               &      -0.0461  &        0.003     &   -14.521  &         0.000        &       -0.052    &       -0.040     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       &  0.766 & \\textbf{  Durbin-Watson:     } &    1.988  \\\\\n",
       "\\textbf{Prob(Omnibus):} &  0.682 & \\textbf{  Jarque-Bera (JB):  } &    0.810  \\\\\n",
       "\\textbf{Skew:}          &  0.104 & \\textbf{  Prob(JB):          } &    0.667  \\\\\n",
       "\\textbf{Kurtosis:}      &  2.929 & \\textbf{  Cond. No.          } & 1.91e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.91e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                  Sales   R-squared:                       0.872\n",
       "Model:                            OLS   Adj. R-squared:                  0.870\n",
       "Method:                 Least Squares   F-statistic:                     381.4\n",
       "Date:                Fri, 04 Aug 2023   Prob (F-statistic):          1.25e-170\n",
       "Time:                        17:49:15   Log-Likelihood:                -571.24\n",
       "No. Observations:                 400   AIC:                             1158.\n",
       "Df Residuals:                     392   BIC:                             1190.\n",
       "Df Model:                           7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "intercept             5.4752      0.505     10.842      0.000       4.482       6.468\n",
       "CompPrice             0.0926      0.004     22.451      0.000       0.084       0.101\n",
       "Income                0.0158      0.002      8.590      0.000       0.012       0.019\n",
       "Advertising           0.1159      0.008     15.006      0.000       0.101       0.131\n",
       "Price                -0.0953      0.003    -35.699      0.000      -0.101      -0.090\n",
       "ShelveLoc[Good]       4.8357      0.152     31.710      0.000       4.536       5.135\n",
       "ShelveLoc[Medium]     1.9520      0.125     15.569      0.000       1.706       2.198\n",
       "Age                  -0.0461      0.003    -14.521      0.000      -0.052      -0.040\n",
       "==============================================================================\n",
       "Omnibus:                        0.766   Durbin-Watson:                   1.988\n",
       "Prob(Omnibus):                  0.682   Jarque-Bera (JB):                0.810\n",
       "Skew:                           0.104   Prob(JB):                        0.667\n",
       "Kurtosis:                       2.929   Cond. No.                     1.91e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.91e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_predictors = list(Carseats.columns.drop(['Sales','Population', 'Education', 'Urban', 'US']))\n",
    "X = MS(reduced_predictors).fit_transform(Carseats)\n",
    "model = sm.OLS(y, X)\n",
    "rslt = model.fit()\n",
    "rslt.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To compare how each model performs we look at the R-sqaured value. This is a measure of how much the selected model is better fitted to explain changes in sales. **A high R-sqaured value indicates a good fit**. \n",
    "### Seeing that **both models have an R-sqaured of 87%** (both models explains changes in sales equally well), we can **compare the F-statistic**. The smaller model has an F-statistic of 381.4 which is significantly more than the F-statistic of the larger model 243.4, we can conclude that the smaller model is the best model to explain changes in sales and predicting future sales as it is more statistically significant.\n",
    "### Other reasons to select a smaller model is to avoid overfitting the data, helps deal with effects of collinearity, and fewer predictors increases interpretability and clarity in the model. \n",
    "### **Using the smaller model we can extract useful insights:**\n",
    "* ### The price of a car seat has a negative relationship with sales (negative coef e.g -0.0953). This is to say that for every dollar increase in price, sales will drop by 9.53%.\n",
    "* ### A good shelving location is associated with higher sales as compared to a bad shelving location.\n",
    "* ### The coefficient of a medium shelving location is positive but lower than a good shelving location. This is to say that although a medium shelving location increases sales more than a bad location, it is still lower than a good shelving location. \n",
    "* ### The same logic can be applied in interpreting the impact of each features coef"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
